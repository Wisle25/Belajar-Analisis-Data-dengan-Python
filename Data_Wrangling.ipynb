{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/RFEzyaJLrZZhTD+/fUke",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wisle25/Belajar-Analisis-Data-dengan-Python/blob/master/Data_Wrangling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **A. Pengenalan Data Wrangling**\n",
        "![](https://dicoding-web-img.sgp1.cdn.digitaloceanspaces.com/original/academy/dos:f3f295abd04ac10298d1c4ebbe096b5b20230309132906.png)\n",
        "**Data Wrangling** adalah proses untuk **mengumpulkan**, **menilai**, dan **membersihkan** data sebelum digunakan dalam analisis. Tujuannya adalah memastikan data siap digunakan dan bebas dari masalah.\n",
        "\n",
        "### **1. Gathering Data**\n",
        "Proses ini mencakup **pengumpulan data** yang relevan untuk menjawab pertanyaan atau masalah bisnis.\n",
        "\n",
        "### **2. Assessing Data**\n",
        "Pada tahap ini, kita melakukan **penilaian** untuk melihat kualitas data dan menemukan masalah seperti **missing values** atau **unstandard values**.\n",
        "\n",
        "### **3. Cleaning Data**\n",
        "Setelah masalah ditemukan, data harus dibersihkan dari error seperti **missing values** dan **outliers** agar dapat digunakan untuk analisis.\n",
        "\n",
        "### **Resume Singkat**:\n",
        "- **Data Wrangling** adalah proses menyiapkan data untuk analisis.\n",
        "- Ada tiga tahap utama: **Pengumpulan data**, **Penilaian data**, dan **Pembersihan data**.\n",
        "- Setiap tahap bertujuan memastikan data bersih, lengkap, dan sesuai untuk digunakan dalam analisis.\n",
        "\n"
      ],
      "metadata": {
        "id": "WJgxfxE3XcV9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **B. Mengumpulkan Data dan Membaca Tipe Data Menggunakan Pandas**\n",
        "\n",
        "Setelah mengenal proses data wrangling, tahap awalnya dimulai dari **mengumpulkan data**. Sumber data yang sering digunakan oleh praktisi data meliputi:\n",
        "\n",
        "- **Kaggle**: Platform untuk dataset publik, kompetisi, dan berbagi pengetahuan terkait data science.\n",
        "- **UCI Machine Learning Repository**: Repositori publik yang menyediakan berbagai dataset untuk kebutuhan akademik.\n",
        "- **Google Dataset Search**: Search engine dari Google untuk mencari dataset publik.\n",
        "- **Satu Data Indonesia**: Platform pemerintah Indonesia untuk mengelola dan mengakses data pemerintah secara terbuka.\n",
        "\n",
        "Selain data publik, praktisi data juga menggunakan **data internal** yang bersifat privat, disimpan di sistem pengolahan database organisasi.\n",
        "\n",
        "---\n",
        "\n",
        "### **Membaca Berbagai Tipe Data Menggunakan Pandas**\n",
        "\n",
        "**Pandas** adalah library Python yang digunakan untuk **membaca dan memanipulasi data**. Pandas mendukung pembacaan berbagai format berkas seperti:\n",
        "- **CSV (Comma Separated Values)**\n",
        "- **XLSX/XLS** (Spreadsheet dari Microsoft Excel)\n",
        "- **JSON** (JavaScript Object Notation)\n",
        "- **HTML** (HyperText Markup Language)\n",
        "- **XML** (Extensible Markup Language)\n",
        "- **SQL database**: Pandas juga bisa membaca data langsung dari database menggunakan library **SQLAlchemy**.\n",
        "\n",
        "---\n",
        "\n",
        "### **Menggabungkan Beberapa Data Menjadi Satu DataFrame**\n",
        "\n",
        "Ketika menghadapi lebih dari satu tabel data, kita sering kali perlu menggabungkannya. Pandas menyediakan function **merge()** untuk menggabungkan dua DataFrame, yang dikenal dengan **join**. Jenis-jenis join yang umum digunakan adalah:\n",
        "\n",
        "- **Inner Join**: Mengambil nilai yang bersesuaian di kedua tabel.\n",
        "- **Left Join**: Mengambil semua nilai dari tabel kiri, beserta nilai yang bersesuaian dari tabel kanan.\n",
        "- **Right Join**: Mengambil semua nilai dari tabel kanan, beserta nilai yang bersesuaian dari tabel kiri.\n",
        "- **Outer Join**: Mengambil semua nilai dari kedua tabel.\n",
        "\n",
        "---\n",
        "\n",
        "Dengan memahami berbagai sumber data dan cara membaca data menggunakan **Pandas**, Anda dapat mulai mengolah data dari berbagai format dan menggabungkannya menjadi satu DataFrame untuk analisis lebih lanjut.\n"
      ],
      "metadata": {
        "id": "19B-FqlgX_Pk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Menggunakan pandas untuk membaca berbagai tipe data\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# CSV\n",
        "df = pd.read_csv('data.csv', delimited=\",\")\n",
        "\n",
        "# XLSX atau XLS\n",
        "df = pd.read_excel('data.xlsx', sheet_name=\"Sheet1\")\n",
        "\n",
        "# JSON\n",
        "df = pd.read_json('data.json')\n",
        "\n",
        "# HTML\n",
        "url = 'https://www.fdic.gov/resources/resolutions/bank-failures/failed-bank-list'\n",
        "df = pd.read_html(url)[0]\n",
        "\n",
        "# XML\n",
        "df = pd.read_xml('https://www.w3schools.com/xml/books.xml')\n",
        "\n",
        "# Database (membutuhkan library tambahan)\n",
        "import sqlalchemy as sqla\n",
        "\n",
        "db = sqla.create_engine('sqlite://mydata.sqlite') # Contoh koneksi database\n",
        "\n",
        "## DB Table\n",
        "pd.read_sql_table('table_name', db)\n",
        "\n",
        "## Dengan query\n",
        "pd.read_sql_query('SELECT * FROM table_name', db)"
      ],
      "metadata": {
        "id": "mD8cRcMjYaG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **C. Assessing Data**\n",
        "\n",
        "Setelah data dikumpulkan, tahap selanjutnya adalah **assessing data** atau pemeriksaan data. Tujuan dari proses ini adalah mengidentifikasi masalah yang terdapat dalam data dan memastikan kualitasnya sebelum masuk ke tahap analisis.\n",
        "\n",
        "### **Masalah Umum Dijumpai dalam Data**\n",
        "\n",
        "1. **Missing Value**:\n",
        "   - **Missing value** adalah nilai yang hilang dalam data, sering direpresentasikan sebagai NaN dalam Pandas. Masalah ini bisa terjadi karena human error, privasi, atau proses merging.\n",
        "\n",
        "2. **Invalid Value**:\n",
        "   - **Invalid value** adalah nilai yang tidak sesuai dengan ketentuan atau logika. Misalnya, **customer id** yang seharusnya unik tetapi tidak sesuai dengan format.\n",
        "\n",
        "3. **Duplicate Data**:\n",
        "   - **Duplicate data** adalah masalah ketika ada observasi yang memiliki nilai yang sama persis di semua kolom.\n",
        "\n",
        "4. **Inaccurate Value**:\n",
        "   - **Inaccurate value** terjadi ketika nilai yang ada tidak sesuai dengan hasil observasi, biasanya karena kesalahan manusia atau sistem.\n",
        "\n",
        "5. **Inconsistent Value**:\n",
        "   - **Inconsistent value** terjadi karena data yang tidak konsisten dari segi satuan atau format pengumpulan nilai.\n",
        "\n",
        "6. **Outlier**:\n",
        "   - **Outlier** adalah nilai yang sangat jauh dari titik data lain dalam dataset. Metode yang umum digunakan untuk mengidentifikasi outlier adalah **IQR method** atau menggunakan **box plot** untuk representasi visual.\n",
        "\n",
        "### **Metode Interquartile Range (IQR)**\n",
        "Metode **IQR** adalah salah satu cara paling umum untuk mendeteksi outlier. Metode ini fokus pada **rentang tengah** dari data dan membantu mengidentifikasi titik data yang jauh lebih rendah atau jauh lebih tinggi daripada yang lain.\n",
        "\n",
        "Berikut adalah cara kerjanya:\n",
        "\n",
        "1. **Quartiles (Kuartil)**:\n",
        "   - **Q1 (Kuartil Pertama)**: Nilai yang memisahkan 25% data terendah dari sisanya.\n",
        "   - **Q3 (Kuartil Ketiga)**: Nilai yang memisahkan 25% data tertinggi dari sisanya.\n",
        "\n",
        "2. **Interquartile Range (IQR)**:\n",
        "   - **IQR** adalah selisih antara **Q3** dan **Q1**. IQR menunjukkan rentang di mana sebagian besar data berada, yaitu di antara 25% terendah dan 25% tertinggi.\n",
        "\n",
        "3. **Menentukan Outlier**:\n",
        "   - Untuk menentukan **outlier**, kita perlu menghitung **cut-off** atau ambang batas. Biasanya, kita mengambil jarak sebanyak **k kali IQR** (k biasanya bernilai 1.5 s/d 3) dari **Q1** dan **Q3** untuk menentukan ambang batas bawah dan atas.\n",
        "   - Nilai ambang batas dihitung dengan rumus:\n",
        "     - **Ambang batas bawah** = Q1 - (1.5 * IQR)\n",
        "     - **Ambang batas atas** = Q3 + (1.5 * IQR)\n",
        "   - Titik data yang berada **di bawah ambang batas bawah** atau **di atas ambang batas atas** akan dianggap sebagai **outlier**.\n",
        "\n",
        "#### **Contoh Sederhana**:\n",
        "Misalkan kita memiliki data nilai ujian sebagai berikut: **[10, 20, 22, 25, 28, 35, 40, 45, 48, 100]**. Nilai **100** adalah contoh **outlier** karena jauh lebih tinggi dibandingkan nilai-nilai lainnya. Dengan menggunakan metode IQR, kita dapat mengidentifikasi bahwa nilai **100** terletak di luar batas yang wajar.\n",
        "\n",
        "Metode IQR ini sangat berguna dalam mendeteksi outlier dan menjaga agar analisis tetap akurat tanpa terlalu dipengaruhi oleh nilai ekstrem yang mungkin muncul karena kesalahan atau anomali.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Setelah memahami masalah-masalah yang umum dijumpai dalam data, Anda dapat menggunakan berbagai teknik seperti **isnull()** untuk missing values, **duplicated()** untuk data duplikat, dan **IQR method** atau **box plot** untuk outlier.\n"
      ],
      "metadata": {
        "id": "9uakRczKZz9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengecek data dengan pandas\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('any.csv')\n",
        "\n",
        "# Missing value\n",
        "df.isnull().sum()\n",
        "\n",
        "# Duplicate value\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "FZlQdwhKaj5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contoh implementasi IQR method\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "data = {}\n",
        "q25, q75 = np.percentile(data, 25), np.percentile(data, 75)\n",
        "iqr = q75 - q25\n",
        "cutoff = iqr * 1.5 # Ingat! 1.5 adalah k\n",
        "min, max = q25 - cutoff, q75 + cutoff\n",
        "\n",
        "outliers = [x for x in data if x < minumum or x > maximum]"
      ],
      "metadata": {
        "id": "b-L-eUN6cHxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **D. Cleaning Data**\n",
        "\n",
        "Pada tahap ini, kita akan memasuki proses terakhir dalam **data wrangling**, yaitu **pembersihan data**. Proses ini memastikan bahwa data yang akan digunakan dalam analisis bebas dari masalah seperti missing value, outlier, dan data duplikat.\n",
        "\n",
        "### **Tahapan dalam Pembersihan Data**\n",
        "1. **Define**: Merancang tahapan dan metode pembersihan berdasarkan masalah yang ditemukan.\n",
        "2. **Code**: Mengonversi rencana pembersihan menjadi kode program yang dapat dijalankan.\n",
        "3. **Test**: Memeriksa data yang telah dibersihkan untuk memastikan hasilnya sesuai harapan.\n",
        "\n",
        "---\n",
        "\n",
        "### **Mengatasi Missing Value**\n",
        "Terdapat tiga metode utama untuk mengatasi **missing value**:\n",
        "1. **Dropping**:\n",
        "   - Menghapus seluruh baris atau kolom yang memiliki missing value menggunakan **dropna()**. Metode ini mudah tetapi harus mempertimbangkan potensi hilangnya informasi.\n",
        "   \n",
        "2. **Imputation**:\n",
        "   - Mengisi missing value dengan nilai **mean**, **median**, atau **kategori paling sering** menggunakan **fillna()**. Metode ini menjaga data tetap lengkap tetapi bisa memengaruhi variance data.\n",
        "   \n",
        "3. **Interpolation**:\n",
        "   - Menggunakan metode **interpolasi** (linear atau polynomial) untuk menghitung nilai missing value, terutama pada **data time series**.\n",
        "\n",
        "---\n",
        "\n",
        "### **Mengatasi Outlier**\n",
        "Outlier dapat ditangani dengan dua metode utama:\n",
        "1. **Drop**:\n",
        "   - Menghapus baris yang mengandung outlier menggunakan **drop()** untuk mencegah outlier memengaruhi analisis.\n",
        "\n",
        "2. **Imputation**:\n",
        "   - Mengganti outlier dengan nilai tertentu seperti **mean**, **median**, atau **boundary value** menggunakan **mask()**.\n",
        "\n",
        "### **Perbedaan IQR Method dengan Drop dan Imputation untuk Outlier**\n",
        "\n",
        "**IQR Method**:\n",
        "   - **Tujuan**: IQR method digunakan untuk **mengidentifikasi** outlier dengan menghitung rentang antara kuartil pertama (Q1) dan kuartil ketiga (Q3), dikenal sebagai **Interquartile Range (IQR)**.\n",
        "   - **Penggunaan**: Outlier didefinisikan sebagai nilai yang berada di luar rentang ini (di bawah Q1 - 1.5 * IQR atau di atas Q3 + 1.5 * IQR).\n",
        "   - **Poin Kunci**: Metode ini digunakan hanya untuk **mendeteksi** outlier, bukan untuk mengatasinya langsung.\n",
        "\n",
        "**Drop Method**:\n",
        "   - **Tujuan**: Setelah outlier diidentifikasi, metode ini digunakan untuk **menghapus** baris yang mengandung outlier dari dataset.\n",
        "   - **Penggunaan**: Dengan menggunakan **drop()**, baris-baris dengan outlier dihapus dari data.\n",
        "   - **Poin Kunci**: **Drop** adalah metode untuk **menghilangkan** outlier, tetapi bisa mengakibatkan hilangnya data.\n",
        "\n",
        "**Imputation Method**:\n",
        "   - **Tujuan**: Sebagai alternatif dari drop, imputation digunakan untuk **mengganti** outlier dengan nilai yang lebih masuk akal seperti **mean**, **median**, atau **boundary value**.\n",
        "   - **Penggunaan**: Dengan menggunakan **mask()**, nilai outlier diganti dengan nilai yang lebih \"normal\" agar data tetap utuh.\n",
        "   - **Poin Kunci**: **Imputation** menjaga data tetap lengkap dengan mengganti outlier, tetapi bisa memengaruhi akurasi analisis tergantung nilai pengganti yang dipilih.\n",
        "\n",
        "---\n",
        "\n",
        "### **Mengatasi Duplicate Data**\n",
        "Untuk mengatasi **duplicate data**, kita bisa menggunakan metode **drop_duplicates()** yang disediakan oleh pandas, yang secara otomatis akan menghapus baris yang memiliki nilai yang sama di setiap kolom.\n",
        "\n"
      ],
      "metadata": {
        "id": "1TFIfcotd85L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Mengatasi Missing Value ##\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('any.csv')\n",
        "\n",
        "# Dropping\n",
        "df.dropna(axis=0, inplace=True)\n",
        "\n",
        "# Imputation\n",
        "df.age.fillna(value=df.age.mean(), inplace=True)\n",
        "\n",
        "# Interpolation\n",
        "df.close_price.interpolate(method='linear', limit_direction='forward', inplace=True)"
      ],
      "metadata": {
        "id": "HADn8RmJeN4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Mengatasi Outlier ##\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('any.csv')\n",
        "\n",
        "Q1 = (df['TotalCharges']).quantile(0.25)\n",
        "Q3 = (df['TotalCharges']).quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "cutoff = 1.5 * IQR\n",
        "min, max = Q1 - cutoff, Q3 + cutoff\n",
        "\n",
        "lower = df['TotalCharges'] < min\n",
        "more = df['TotalCharges'] > max\n",
        "\n",
        "# Drop\n",
        "df.drop(df[lower].index, inplace=True)\n",
        "df.drop(df[more].index, inplace=True)\n",
        "\n",
        "# Imputation\n",
        "df.mask(cond=more, max, axis=1, inplace=True)\n",
        "df.mask(cond=lower, min, axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "ddYyozn5eyKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Mengatasi Duplicate Data ##\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('any.csv')\n",
        "df.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "0niDj03Sfpfy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}